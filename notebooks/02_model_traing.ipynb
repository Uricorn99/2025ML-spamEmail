{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fffed272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working dir: c:\\Users\\PC\\Desktop\\2025ML-spamEmail\\notebooks\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports & basic settings\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "import joblib\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# 確保我們是從 notebooks/ 底下在跑\n",
    "import os\n",
    "print(\"Current working dir:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7990cbae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Loaded TF-IDF train/test split from: ../models/train_test_tfidf.pkl\n",
      "X_train_tfidf shape: (4458, 12076)\n",
      "X_test_tfidf  shape: (1115, 12076)\n",
      "y_train length: 4458\n",
      "y_test  length: 1115\n",
      "\n",
      ">>> First 10 labels in y_train: ['ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'ham']\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load preprocessed train/test data (TF-IDF)\n",
    "\n",
    "tfidf_split_path = \"../models/train_test_tfidf.pkl\"\n",
    "\n",
    "X_train_tfidf, X_test_tfidf, y_train, y_test = joblib.load(tfidf_split_path)\n",
    "\n",
    "print(\">>> Loaded TF-IDF train/test split from:\", tfidf_split_path)\n",
    "print(\"X_train_tfidf shape:\", X_train_tfidf.shape)\n",
    "print(\"X_test_tfidf  shape:\", X_test_tfidf.shape)\n",
    "print(\"y_train length:\", len(y_train))\n",
    "print(\"y_test  length:\", len(y_test))\n",
    "\n",
    "print(\"\\n>>> First 10 labels in y_train:\", y_train[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b273d70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Helper function to train & evaluate a model\n",
    "\n",
    "def train_and_evaluate_model(model, model_name, X_train, y_train, X_test, y_test, pos_label=\"spam\"):\n",
    "    \"\"\"\n",
    "    訓練單一模型並計算 metrics。\n",
    "    回傳一個 dict: { \"model\": model, \"name\": model_name, \"accuracy\": ..., ... }\n",
    "    \"\"\"\n",
    "    print(f\"\\n========== {model_name} ==========\")\n",
    "    \n",
    "    # 訓練\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 預測\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # 如果 label 是文字（spam / ham），我們假設 spam 是 positive class\n",
    "    # 若你的資料標記不同，可以改 pos_label\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    try:\n",
    "        precision = precision_score(y_test, y_pred, pos_label=pos_label)\n",
    "        recall = recall_score(y_test, y_pred, pos_label=pos_label)\n",
    "        f1 = f1_score(y_test, y_pred, pos_label=pos_label)\n",
    "    except Exception as e:\n",
    "        # 如果 pos_label 不存在，就用 macro average 當 fallback\n",
    "        print(\"Warning: binary precision/recall failed, fallback to macro average. Error:\", e)\n",
    "        precision = precision_score(y_test, y_pred, average=\"macro\")\n",
    "        recall = recall_score(y_test, y_pred, average=\"macro\")\n",
    "        f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    \n",
    "    print(\"Accuracy :\", round(accuracy, 4))\n",
    "    print(\"Precision:\", round(precision, 4))\n",
    "    print(\"Recall   :\", round(recall, 4))\n",
    "    print(\"F1-score :\", round(f1, 4))\n",
    "    \n",
    "    print(\"\\nClassification report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion matrix:\\n\", cm)\n",
    "    \n",
    "    return {\n",
    "        \"name\": model_name,\n",
    "        \"model\": model,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"confusion_matrix\": cm,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37c129e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Logistic Regression ==========\n",
      "Accuracy : 0.974\n",
      "Precision: 0.9918\n",
      "Recall   : 0.8121\n",
      "F1-score : 0.893\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.99       966\n",
      "        spam       0.99      0.81      0.89       149\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.98      0.91      0.94      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n",
      "Confusion matrix:\n",
      " [[965   1]\n",
      " [ 28 121]]\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Train Logistic Regression\n",
    "\n",
    "log_reg = LogisticRegression(\n",
    "    solver=\"liblinear\",       # 適合小型/中型 dataset\n",
    "    max_iter=1000,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "log_reg_result = train_and_evaluate_model(\n",
    "    model=log_reg,\n",
    "    model_name=\"Logistic Regression\",\n",
    "    X_train=X_train_tfidf,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test_tfidf,\n",
    "    y_test=y_test,\n",
    "    pos_label=\"spam\",  # 如果資料不是 spam/ham，可以改\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9a43b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Multinomial Naive Bayes ==========\n",
      "Accuracy : 0.9677\n",
      "Precision: 1.0\n",
      "Recall   : 0.7584\n",
      "F1-score : 0.8626\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      1.00      0.98       966\n",
      "        spam       1.00      0.76      0.86       149\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.98      0.88      0.92      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n",
      "Confusion matrix:\n",
      " [[966   0]\n",
      " [ 36 113]]\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Train Multinomial Naive Bayes\n",
    "\n",
    "nb_clf = MultinomialNB()\n",
    "\n",
    "nb_result = train_and_evaluate_model(\n",
    "    model=nb_clf,\n",
    "    model_name=\"Multinomial Naive Bayes\",\n",
    "    X_train=X_train_tfidf,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test_tfidf,\n",
    "    y_test=y_test,\n",
    "    pos_label=\"spam\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bab9ee75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Linear SVM (LinearSVC) ==========\n",
      "Accuracy : 0.9865\n",
      "Precision: 0.9786\n",
      "Recall   : 0.9195\n",
      "F1-score : 0.9481\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      1.00      0.99       966\n",
      "        spam       0.98      0.92      0.95       149\n",
      "\n",
      "    accuracy                           0.99      1115\n",
      "   macro avg       0.98      0.96      0.97      1115\n",
      "weighted avg       0.99      0.99      0.99      1115\n",
      "\n",
      "Confusion matrix:\n",
      " [[963   3]\n",
      " [ 12 137]]\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Train Linear SVM (LinearSVC)\n",
    "\n",
    "svm_clf = LinearSVC(\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "svm_result = train_and_evaluate_model(\n",
    "    model=svm_clf,\n",
    "    model_name=\"Linear SVM (LinearSVC)\",\n",
    "    X_train=X_train_tfidf,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test_tfidf,\n",
    "    y_test=y_test,\n",
    "    pos_label=\"spam\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed5fc0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Model comparison (sorted by F1-score):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linear SVM (LinearSVC)</td>\n",
       "      <td>0.986547</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.919463</td>\n",
       "      <td>0.948097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.973991</td>\n",
       "      <td>0.991803</td>\n",
       "      <td>0.812081</td>\n",
       "      <td>0.892989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>0.967713</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.758389</td>\n",
       "      <td>0.862595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model  accuracy  precision    recall        f1\n",
       "2   Linear SVM (LinearSVC)  0.986547   0.978571  0.919463  0.948097\n",
       "0      Logistic Regression  0.973991   0.991803  0.812081  0.892989\n",
       "1  Multinomial Naive Bayes  0.967713   1.000000  0.758389  0.862595"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Best model based on F1-score: Linear SVM (LinearSVC)\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Compare models\n",
    "\n",
    "results = [log_reg_result, nb_result, svm_result]\n",
    "\n",
    "# 用 pandas 整理成表格\n",
    "summary_rows = []\n",
    "for r in results:\n",
    "    summary_rows.append({\n",
    "        \"model\": r[\"name\"],\n",
    "        \"accuracy\": r[\"accuracy\"],\n",
    "        \"precision\": r[\"precision\"],\n",
    "        \"recall\": r[\"recall\"],\n",
    "        \"f1\": r[\"f1\"],\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "summary_df = summary_df.sort_values(by=\"f1\", ascending=False)\n",
    "\n",
    "print(\">>> Model comparison (sorted by F1-score):\")\n",
    "display(summary_df)\n",
    "\n",
    "best_model_name = summary_df.iloc[0][\"model\"]\n",
    "print(\"\\n>>> Best model based on F1-score:\", best_model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d354c79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Best model 'Linear SVM (LinearSVC)' has been saved to: ../models/best_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Save the best model to ../models/best_model.pkl\n",
    "\n",
    "# 找出對應的 result object\n",
    "name_to_result = {r[\"name\"]: r for r in results}\n",
    "best_result = name_to_result[best_model_name]\n",
    "best_model = best_result[\"model\"]\n",
    "\n",
    "best_model_path = \"../models/best_model.pkl\"\n",
    "joblib.dump(best_model, best_model_path)\n",
    "\n",
    "print(f\">>> Best model '{best_model_name}' has been saved to: {best_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "929fb3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "Message: WIN a FREE iPhone now!!! Click this link!\n",
      "Predicted label: spam\n",
      "-----\n",
      "Message: Hey, are we still meeting for lunch tomorrow?\n",
      "Predicted label: ham\n",
      "-----\n",
      "Message: Congratulations, you have won a lottery! Reply with your bank details.\n",
      "Predicted label: spam\n"
     ]
    }
   ],
   "source": [
    "# Cell 9 (Optional): Quick manual test with a few example messages\n",
    "\n",
    "# 載入已存好的 vectorizer\n",
    "vectorizer_path = \"../models/tfidf_vectorizer.pkl\"\n",
    "tfidf_loaded = joblib.load(vectorizer_path)\n",
    "\n",
    "test_messages = [\n",
    "    \"WIN a FREE iPhone now!!! Click this link!\",\n",
    "    \"Hey, are we still meeting for lunch tomorrow?\",\n",
    "    \"Congratulations, you have won a lottery! Reply with your bank details.\",\n",
    "]\n",
    "\n",
    "X_test_manual = tfidf_loaded.transform(test_messages)\n",
    "preds = best_model.predict(X_test_manual)\n",
    "\n",
    "for msg, pred in zip(test_messages, preds):\n",
    "    print(\"-----\")\n",
    "    print(\"Message:\", msg)\n",
    "    print(\"Predicted label:\", pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
