import os
import re
from collections import Counter
from typing import List, Tuple

import joblib
import numpy as np
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    confusion_matrix,
    classification_report,
    roc_curve,
    auc,
    precision_recall_curve,
    average_precision_score,
    precision_score,
    recall_score,
    f1_score,
)


# =========================
# Streamlit åŸºæœ¬è¨­å®š
# =========================
st.set_page_config(
    page_title="SMS Spam Classifier â€” Dashboard",
    page_icon="ğŸ“¨",
    layout="wide",
)


# =========================
# æ–‡å­—æ¸…ç†ï¼šå’Œ 01_preprocess.ipynb ä¸€è‡´çš„ç°¡åŒ–ç‰ˆæœ¬
# =========================
def clean_text(text: str) -> str:
    text = text.lower().strip()
    text = re.sub(r"[^a-z0-9\s]", " ", text)
    text = re.sub(r"\s+", " ", text)
    return text


# =========================
# è¼‰å…¥è³‡æ–™ / æ¨¡å‹ / å‘é‡å™¨ï¼ˆåŠ  cacheï¼‰
# =========================
@st.cache_data(show_spinner=False)
def load_dataset(path: str) -> pd.DataFrame:
    return pd.read_csv(path)


@st.cache_resource(show_spinner=False)
def load_vectorizer_and_model():
    vec_path = os.path.join("models", "tfidf_vectorizer.pkl")
    model_path = os.path.join("models", "best_model.pkl")

    vectorizer = joblib.load(vec_path)
    model = joblib.load(model_path)
    return vectorizer, model


def token_topn(series: pd.Series, topn: int) -> List[Tuple[str, int]]:
    counter: Counter = Counter()
    for s in series.astype(str):
        counter.update(s.split())
    return counter.most_common(topn)


# =========================
# åˆå§‹åŒ–ï¼šè¼‰å…¥ artifacts
# =========================
vectorizer, model = load_vectorizer_and_model()


# =========================
# Sidebarï¼šåŸºæœ¬æ§åˆ¶é …
# =========================
with st.sidebar:
    st.header("è¨­å®š / Inputs")

    data_path = st.text_input(
        "Dataset CSV è·¯å¾‘",
        value="data/sms_spam_no_header.csv",
        help="ç›¸å°æ–¼å°ˆæ¡ˆæ ¹ç›®éŒ„çš„è·¯å¾‘",
    )

    df = load_dataset(data_path)

    # çŒœ label / text æ¬„ä½ï¼ˆç°¡åŒ–ç‰ˆï¼‰
    cols = list(df.columns)
    label_candidates = [c for c in cols if c.lower() in ("label", "target", "col_0")]
    text_candidates = [c for c in cols if c.lower() in ("text", "message", "text_clean", "col_1")]

    default_label = label_candidates[0] if label_candidates else cols[0]
    default_text = text_candidates[0] if text_candidates else cols[-1]

    label_col = st.selectbox("Label æ¬„ä½", options=cols, index=cols.index(default_label))
    text_col = st.selectbox("æ–‡å­—æ¬„ä½", options=cols, index=cols.index(default_text))

    # é¸æ­£é¡ï¼ˆå¤šåŠæ˜¯ spamï¼‰
    unique_labels = sorted(df[label_col].astype(str).unique().tolist())
    default_pos = "spam" if "spam" in [u.lower() for u in unique_labels] else unique_labels[0]
    # æ‰¾å‡º default_pos å°æ‡‰çš„åŸå§‹å¤§å°å¯«
    for u in unique_labels:
        if u.lower() == default_pos.lower():
            default_pos = u
            break

    pos_label = st.selectbox("Positive classï¼ˆæ­£é¡ï¼Œé€šå¸¸æ˜¯ spamï¼‰", options=unique_labels, index=unique_labels.index(default_pos))

    test_size = st.slider("Test size", min_value=0.1, max_value=0.4, value=0.2, step=0.05)
    seed = st.number_input("Random seed", min_value=0, value=42, step=1)
    threshold = st.slider("æ±ºç­–é–¾å€¼ï¼ˆthresholdï¼‰", min_value=0.1, max_value=0.9, value=0.5, step=0.05)

    topn_tokens = st.slider("Top-N tokens (per class)", min_value=10, max_value=40, value=20, step=5)


# =========================
# ä¸»æ¨™é¡Œ
# =========================
st.title("ğŸ“¨ SMS Spam Classifier â€” Dashboard")
st.caption("Data distribution Â· Token patterns Â· Model performance Â· Live inference")

st.markdown("---")


# =========================
# å€å¡Šä¸€ï¼šData Overview
# =========================
st.subheader("1. Data Overview")

c1, c2 = st.columns(2)

with c1:
    st.write("Class distribution")
    label_counts = df[label_col].value_counts().sort_index()
    st.bar_chart(label_counts)

with c2:
    st.write("Dataset head")
    st.dataframe(df.head())


st.markdown("---")


# =========================
# å€å¡ŠäºŒï¼šTop Tokens by Classï¼ˆå¤§è‡´ä»¿è€å¸«ç¯„ä¾‹ï¼‰
# =========================
st.subheader("2. Top Tokens by Class (ç°¡å–® token çµ±è¨ˆ)")

# å…ˆå»ºç«‹æ¸…ç†éæ–‡å­—æ¬„ä½
df["_clean_text_for_tokens"] = df[text_col].astype(str).apply(clean_text)

col_a, col_b = st.columns(2)
classes_for_top = list(label_counts.index[:2])  # å–å‰å…©å€‹é¡åˆ¥å±•ç¤ºï¼ˆå¤šåŠå°±æ˜¯ ham + spamï¼‰

for label, col in zip(classes_for_top, [col_a, col_b]):
    with col:
        st.write(f"Class: **{label}**")
        subset = df.loc[df[label_col] == label, "_clean_text_for_tokens"]
        top_tokens = token_topn(subset, topn_tokens)
        if top_tokens:
            toks, freqs = zip(*top_tokens)
            fig, ax = plt.subplots(figsize=(6, 4))
            sns.barplot(x=list(freqs), y=list(toks), ax=ax)
            ax.set_xlabel("Frequency")
            ax.set_ylabel("Token")
            st.pyplot(fig)
        else:
            st.info("No tokens found for this class.")

st.markdown("---")


# =========================
# å€å¡Šä¸‰ï¼šModel Performanceï¼ˆConfusion matrix, ROC, PR, Threshold sweepï¼‰
# =========================
st.subheader("3. Model Performance on Test Split")

# å»ºç«‹ä¹¾æ·¨æ–‡å­— + label
X_all = df[text_col].astype(str).apply(clean_text)
y_all = df[label_col].astype(str)

# train/test splitï¼ˆæ³¨æ„è¦ stratifyï¼‰
X_tr, X_te, y_tr, y_te = train_test_split(
    X_all,
    y_all,
    test_size=test_size,
    random_state=seed,
    stratify=y_all,
)

# vectorize æ¸¬è©¦é›†
X_te_vec = vectorizer.transform(X_te)

# äºŒå…ƒ 0/1 label for curves
y_true_binary = np.array([1 if y == pos_label else 0 for y in y_te])

# å–å¾— scores / probabilities
y_scores = None
use_proba = False

if hasattr(model, "predict_proba"):
    proba = model.predict_proba(X_te_vec)
    classes = list(model.classes_)
    if pos_label in classes:
        pos_idx = classes.index(pos_label)
    else:
        pos_idx = 1 if len(classes) > 1 else 0
    y_scores = proba[:, pos_idx]
    use_proba = True
elif hasattr(model, "decision_function"):
    y_scores = model.decision_function(X_te_vec)
    use_proba = False

# æ ¹æ“š threshold åšé æ¸¬ï¼ˆå¦‚æœæœ‰ scoreï¼‰
if y_scores is not None:
    y_pred_binary = (y_scores >= threshold).astype(int)
    # å°æ‡‰å› label
    # æ‰¾ä¸€å€‹ã€Œåé¡ã€åç¨±
    neg_label = [c for c in unique_labels if c != pos_label]
    neg_label = neg_label[0] if neg_label else f"not_{pos_label}"
    y_pred_labels = np.where(y_pred_binary == 1, pos_label, neg_label)
else:
    # fallbackï¼šç›´æ¥ç”¨ model.predict çš„ label ç•¶ä½œé æ¸¬
    y_pred_labels = model.predict(X_te_vec)
    # åŒæ™‚è½‰ 0/1ï¼Œæ–¹ä¾¿å¾Œé¢è‡³å°‘ç•« confusion matrix
    y_pred_binary = np.array([1 if y == pos_label else 0 for y in y_pred_labels])

# ---- Confusion matrixï¼ˆlabel ç‰ˆæœ¬ï¼‰ ----
cm = confusion_matrix(y_te, y_pred_labels, labels=unique_labels)
cm_df = pd.DataFrame(cm, index=[f"true_{l}" for l in unique_labels], columns=[f"pred_{l}" for l in unique_labels])

c3, c4 = st.columns(2)
with c3:
    st.write(" Confusion Matrix (table)")
    st.dataframe(cm_df)

with c4:
    st.write(" Confusion Matrix (heatmap)")
    fig_cm, ax_cm = plt.subplots(figsize=(5, 4))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
                xticklabels=unique_labels, yticklabels=unique_labels, ax=ax_cm)
    ax_cm.set_xlabel("Predicted")
    ax_cm.set_ylabel("True")
    st.pyplot(fig_cm)

# ---- ROC & PR curvesï¼ˆå¦‚æœæœ‰ scoreï¼‰----
if y_scores is not None:
    fpr, tpr, _ = roc_curve(y_true_binary, y_scores)
    roc_auc = auc(fpr, tpr)

    prec, rec, _ = precision_recall_curve(y_true_binary, y_scores)
    ap = average_precision_score(y_true_binary, y_scores)

    fig_curves, (ax_roc, ax_pr) = plt.subplots(1, 2, figsize=(10, 4))

    # ROC
    ax_roc.plot(fpr, tpr, label=f"AUC = {roc_auc:.3f}")
    ax_roc.plot([0, 1], [0, 1], linestyle="--", color="gray")
    ax_roc.set_title("ROC Curve")
    ax_roc.set_xlabel("False Positive Rate")
    ax_roc.set_ylabel("True Positive Rate")
    ax_roc.legend(loc="lower right")

    # PR
    ax_pr.plot(rec, prec, label=f"AP = {ap:.3f}")
    ax_pr.set_title("Precisionâ€“Recall Curve")
    ax_pr.set_xlabel("Recall")
    ax_pr.set_ylabel("Precision")
    ax_pr.legend(loc="lower left")

    st.pyplot(fig_curves)

    # ---- Threshold sweep ----
    st.write(" Threshold sweep (precision / recall / f1)")
    ths = np.round(np.linspace(0.3, 0.8, 11), 3)
    rows = []
    for t in ths:
        p_bin = (y_scores >= t).astype(int)
        rows.append({
            "threshold": float(t),
            "precision": float(precision_score(y_true_binary, p_bin, zero_division=0)),
            "recall": float(recall_score(y_true_binary, p_bin, zero_division=0)),
            "f1": float(f1_score(y_true_binary, p_bin, zero_division=0)),
        })
    st.dataframe(pd.DataFrame(rows))
else:
    st.info("ç•¶å‰ best_model ä¸æ”¯æ´ predict_proba / decision_functionï¼Œç„¡æ³•ç¹ªè£½ ROC / PR / threshold sweepã€‚")


st.markdown("---")


# =========================
# å€å¡Šå››ï¼šLive Inferenceï¼ˆäº’å‹•é æ¸¬ï¼‰
# =========================
st.subheader("4. Live Inferenceï¼ˆå³æ™‚é æ¸¬ï¼‰")

ex_spam = "Free entry in a weekly contest to win cash now! Click the link to claim your prize."
ex_ham = "Hi, I will arrive around 7 pm, see you then."

c_ex1, c_ex2 = st.columns(2)
with c_ex1:
    if st.button("å¡«å…¥ spam ç¯„ä¾‹"):
        st.session_state["input_text"] = ex_spam
with c_ex2:
    if st.button("å¡«å…¥ ham ç¯„ä¾‹"):
        st.session_state["input_text"] = ex_ham

if "input_text" not in st.session_state:
    st.session_state["input_text"] = ""

user_text = st.text_area("è«‹è¼¸å…¥è¦åˆ†é¡çš„è¨Šæ¯ï¼ˆSMSï¼‰ï¼š", key="input_text", height=100)

if st.button("é æ¸¬"):
    if user_text.strip():
        clean_user = clean_text(user_text)
        with st.expander("é¡¯ç¤ºæ¸…ç†å¾Œçš„æ–‡å­—", expanded=False):
            st.code(clean_user)

        X_single = vectorizer.transform([clean_user])

        pred_label = model.predict(X_single)[0]
        score_display = None

        if hasattr(model, "predict_proba"):
            proba_single = model.predict_proba(X_single)[0]
            classes = list(model.classes_)
            if pos_label in classes:
                idx_pos = classes.index(pos_label)
            else:
                idx_pos = 1 if len(classes) > 1 else 0
            score_display = float(proba_single[idx_pos])
        elif hasattr(model, "decision_function"):
            score_display = float(model.decision_function(X_single)[0])

        if str(pred_label).lower() == str(pos_label).lower():
            st.error(f"é æ¸¬çµæœï¼š**{pred_label}**  ï¼ˆpositive class: {pos_label}ï¼‰")
        else:
            st.success(f"é æ¸¬çµæœï¼š**{pred_label}** ")

        if score_display is not None:
            if use_proba:
                st.write(f"æ¨¡å‹å° **{pos_label}** çš„ä¿¡å¿ƒï¼ˆæ©Ÿç‡ï¼‰ï¼š**{score_display:.4f}**")
            else:
                st.write(f"æ¨¡å‹ decision scoreï¼š**{score_display:.4f}**")
    else:
        st.info("è«‹å…ˆè¼¸å…¥éç©ºç™½è¨Šæ¯ã€‚")

st.markdown("---")
st.caption("Homework 3 â€” SMS Spam Classification Â· Streamlit Visual Dashboard")
